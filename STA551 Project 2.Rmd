---
title: 'Election 2020 Voters Explatory Data Analysis'
author: "Steven Raimondo"
date: " 22-Sep-2024"
output:
  word_document: 
    toc: yes
    toc_depth: 4
    fig_caption: yes
    keep_md: yes
  html_document: 
    toc: yes
    toc_depth: 4
    toc_float: yes
    number_sections: yes
    toc_collapsed: yes
    code_folding: hide
    code_download: yes
    smooth_scroll: yes
    theme: lumen
  pdf_document: 
    toc: yes
    toc_depth: 4
    fig_caption: yes
    number_sections: yes
    fig_width: 3
    fig_height: 3
editor_options: 
  chunk_output_type: inline
---


```{=html}

<style type="text/css">

/* Cascading Style Sheets (CSS) is a stylesheet language used to describe the presentation of a document written in HTML or XML. it is a simple mechanism for adding style (e.g., fonts, colors, spacing) to Web documents. */

h1.title {  /* Title - font specifications of the report title */
  font-size: 24px;
  font-weight:bold;
  color: DarkRed;
  text-align: center;
  font-family: "Gill Sans", sans-serif;
}
h4.author { /* Header 4 - font specifications for authors  */
  font-size: 20px;
  font-family: system-ui;
  color: DarkRed;
  text-align: center;
}
h4.date { /* Header 4 - font specifications for the date  */
  font-size: 18px;
  font-family: system-ui;
  color: DarkBlue;
  text-align: center;
}
h1 { /* Header 1 - font specifications for level 1 section title  */
    font-size: 22px;
    font-family: system-ui;
    font-weight:bold;
    color: navy;
    text-align: left;
}
h2 { /* Header 2 - font specifications for level 2 section title */
    font-size: 20px;
    font-weight:bold;
    font-family: "Times New Roman", Times, serif;
    color: navy;
    text-align: left;
}

h3 { /* Header 3 - font specifications of level 3 section title  */
    font-size: 18px;
    font-weight:bold;
    font-family: "Times New Roman", Times, serif;
    color: navy;
    text-align: left;
}

h4 { /* Header 4 - font specifications of level 4 section title  */
    font-size: 16px;
    font-family: "Times New Roman", Times, serif;
    color: darkred;
    text-align: left;
}

body { background-color:white; }

.highlightme { background-color:yellow; }

p { background-color:white; }

</style>
```


```{r setup, include=FALSE}
options(repos = list(CRAN="http://cran.rstudio.com/"))
# code chunk specifies whether the R code, warnings, and output 
# will be included in the output files.
if (!require("knitr")) {
   install.packages("knitr")
   library(knitr)
}
if (!require("tidyverse")) {
   install.packages("tidyverse")
library(tidyverse)
}
if (!require("GGally")) {
   install.packages("GGally")
library(GGally)
}
if (!require("ggridges")) {
   install.packages("ggridges")
   library(ggridges)
}
knitr::opts_chunk$set(echo = TRUE,       
                      warning = FALSE,   
                      result = TRUE,   
                      message = FALSE,
                      comment = NA)
```


\

# Introduction

Exploratory Data Analysis (EDA) is an important aspect of data science that focuses on summarizing and extracting key features of a dataset. This is often done through visual methods or way of summary statistics. The main objectives of EDA include:

**Understanding Data Structure**: EDA provides insights into the dataâ€™s underlying structure, such as its distribution, patterns, and anomalies

**Identifying Relationships**: It helps uncover relationships between variables

**Detecting Outliers**: It aids in identifying outliers that could impact model performance

**Checking Assumptions**: It is used to verify the assumptions necessary for statistical tests and models

By utilizing the aforementioned objectives through EDA, we're able to determine the right techniques to extract additional insights from our data. This inevitably leads to an enhanced performance of subsequent modeling and analysis

## Problem Statement & Background
In this case study, we will use publicly available data from 4 separate datasets that has been combined into one dataset to demonstrate exploratory data analysis regarding voting and supporting data surrounding the 2020 election. We will examine voting tendencies across the United States and how they are affected by way of geographically, socioeconomically, and educationally

### Software System

**R (Programming Language)** was exclusively used to perform this analysis. R is an open-source and free software system  for statistical computing and data visualization. The availability to all persons enables users across the globe to view, reproduce, and collaborate with ease and thus is an optimal choice for programming language to be utilized

# Description of the Data

The combined dataset renamed **US_Election2020** provides an overview of winning party voting patterns across across various counties in the USA. The 4 datasets that were utilized to create the combined dataset each served it's own purpose in feeding into the created combined dataset

**Presidential Election Data**: Only data from the 2020 election was taken from this dataset. The winning party either republican or democrat with the total votes added up were kept along with the FIPS code, state name, and county name

**Unemployment Data**: Only the unemployment date in the year 2020 or the most recent year if the 2020 unemployment rate is unavailable was used to keep the county FIPS code and the unemployment rate

**Poverty Data**: The 2019 poverty rate and county FIPS code was extracted from the poverty dataset

**Education Data**: The education levels between the years 2015 were used to keep the percent of individuals in the county FIPS who had less than a high school diploma, high school diploma, completed some college, and was a college graduate

There are several predictor variables that are crucial in this datasets EDA that will assist in predicting a winning party should subsequent in-depth analysis should be performed. The types of data that is used in assisting a model is crucial to help show how trends in the explanatory variables can affect the outcome. This dataset was built to lean on some historically important information when it comes to voters' tendencies, some of which is the education level, unemployment, rate, and poverty rate in a particular geographical area.  A detailed description of the variables is given below

# US_Voting_Data TELL what is the response variable
'FIPS_Code': Federal Information Processing Standard - A unique code that identifies counties and county equivalents in the United States

'state': The name of the state in the data from the United States

'county_name': The name of the county within the state

'total_votes': The number of votes the winning party received in that county

'party': The name of the winning political party whether it be Republican or Democrat

'unemployment_rate': The unemployment rate in the corresponding FIPS_code

'poverty_rate': The poverty rate in the corresponding FIPS_code

'Some_High_School': The percentage of voters in the corresponding FIPS_Code who's highest level of education is some high school

'High_School_Diploma': The percentage of voters in the corresponding FIPS_Code who's highest level of education is a high school diploma

'Some_College': The percentage of voters in the corresponding FIPS_Code who's highest level of education is some college

'College_Graduate': The percentage of voters in the corresponding FIPS_Code who's highest level of education is college graduate

## Missing Values

The below summary table of the data indicates that the variable 'FIPS_Code' has 2 missing values, while 'unemployment_rate', 'poverty_rate',
,'Some_High_School', 'High_School_Diploma', 'Some_College', and 'College_Graduate' all have 41 missing values. We will impute the missing values


\
{}

```{r}
setwd("C:/Users/frvas/Desktop/STA551/Week3")
Combined_Data <- read.csv("combined_data.csv")
US_Election2020 <- Combined_Data
summary(US_Election2020)
```

There are 41 rows that have missing values in the US_Election2020 dataset.The District of Columbia and the federal precinct of Rhode Island do not contain an FIPS_Code. The state of Alaska counts for 38 of the rows with a great number of missing values for the variables and the South Dakota has 1 FIPS_Code that has no data for unemployment, poverty, and education levels.

```{r}
Missing_Values <- US_Election2020[apply(is.na(US_Election2020), 1, any), ]
```
### Dealing with Missing Values

While there is data for the District of Columbia in terms of unemployment, poverty, and education there is no FIPS_Code for the county in the election dataset we used to combine. Therefore, we can't be certain which FIPS_Codes in the other datasets correlate with the election dataset. We will drop DC from our future analysis for this reason along with it is not a true state. Additionally, the Federal precinct of Rhode Island will be dropped as this is not a real county. We would look into possibly keeping these datapoints in future analysis should we be able to consult with a subject matter expert and get their opinion on voting election data results. 

The state of Alaska has missing data for 38 of the 41 observations. The geographic isolation of the state would make imputation irresponsible as we can't use surrounding states data to help impute. The data in Alaska very much might be significantly different than what we would hope to impute. I would further consult with a subject matter expert to help ascertain more voting information for the state and see how they correspond the the FIPS_Code as there seems to be a large amount missing in the election data. Therefore, I will remove the state of Alaska from any subsequent EDA as 3 counties will provide an inadequate amount of data to represent the state in our EDA.

Lastly, for FIPS_Code 46113: South Dakota we will impute the missing values using K-Nearest Neighbors (KNN) which utilizes the distances data points are away from each other and determines which datapoints are closest to the missing values and by impute them. For example, R will use the data in total_votes to find the nearest neighbors to FIPS_Code: 46113 and impute them as this method tells us that they should have similar values as their neighbors.

-- Removing the rows that are missing values for FIPS_Code & removing Alaska from the dataset
```{r}
US_Election2020 <- US_Election2020[complete.cases(US_Election2020$FIPS_Code), ]

US_Election2020 <- US_Election2020[US_Election2020$state != "ALASKA", ]
```

-- Filtering out South Dakota data
```{r}
library(dplyr)

SD_Data <- US_Election2020 %>% 
  filter(state == "SOUTH DAKOTA")
```

-- Using KNN to impute the missing values
```{r}
library(VIM)
SD_Data_I <- kNN(SD_Data, k = 5)
print(SD_Data_I[SD_Data_I$FIPS_Code == 46113, ])
```
-- Inputting the imputed data back into the US_Election2020 dataset and renaming it to Election2020. We will use this dataset going forth for EDA. We now see there are no more missing values.
```{r}
Update <- which(US_Election2020$FIPS_Code == 46113)
if (length(Update) > 0) {US_Election2020[Update, c("unemployment_rate", "poverty_rate", "Some_High_School", "High_School_Diploma", "Some_College", "College_Graduate")] <- 
    c(7.8, 39.8, 15.9, 35.9, 32.4, 16.4)}

Election2020 <- US_Election2020

print(Election2020[Update, ])
summary(Election2020)

```

# Explatory Data Analysis

A good start to EDA is to look at the distribution of some key variables. We can see via the barchart below there is a lot more republican datapoints in the dataset than democrats.

```{r}
library(dplyr)

ggplot(Election2020, aes(x = party)) +
 geom_bar(fill = "Blue") +
 geom_text(stat = 'count', aes(label = ..count..),  vjust = -.4,  color = "black") +
  labs(title = "Distribution of Party",
       x = "Party",
       y = "Count")

```

--However upon closer examination if we count up the total votes we see there are far more democrat total votes

```{r}
library(dplyr)

Total_Party_Votes <- Election2020 %>%
  group_by(party) %>%
  summarise(total_votes = sum(total_votes, na.rm = TRUE))

ggplot(Total_Party_Votes, aes(x = party, y = total_votes, fill = party)) +
  geom_bar(fill= "Blue",stat = "identity") +
  labs(title = "Total Party Votes",
       x = "Party",
       y = "Total Votes") +
  geom_text(aes(label = total_votes), vjust = -0.4)

```

A very useful approach to EDA is understanding how each of the variables relate to one another, and we can do that by looking at how much closely they are correlated. We see as we would expect that unemployment rate and poverty rate are positively correlated. We also see that as the education level of a voter rises, the poverty rate drops.
```{r}
library(GGally)
ggpairs(Election2020 %>% select(party, poverty_rate, unemployment_rate, Some_High_School, High_School_Diploma, Some_College, College_Graduate))
```

### Subsubsection - Level 3 Header

## Subsection - Level 2 Header

### Subsubsection - Level 3 Header

## Subsection - Level 2 Header

\

# Appendix - R Code

Below I'm setting the working directory and loading the 4 datasets I plan to use to combine into 1 dataset.

```{r, results=FALSE}
setwd("C:/Users/frvas/Desktop/STA551/Week3")
Election <- read.csv("countypresidential_election_2000-2020.csv")
Education <- read.csv("Education.csv")
Poverty <- read.csv("PovertyEstimates.csv")
Unemployment1 <- read.csv("Unemployment.csv")
```

Next I'm loading the library dplyr to assist with extracting the data I want from the **Election** dataset.
- Rename the dataset as to not alter the original
- Filter and keep only data rows that have 2020 in the year column
- Filter and keep only data rows that have Democrat or Republican in the party column
- Add up the total votes by county and part
- Determine the winning party based on total votes and keep the winning party along with county_fips, state, county_name information
- Look at the 1st 5 entries of the new dataset. I'm hiding the output with results=FALSE to make it cleaner to read for the final document.

```{r, results=FALSE}
library(dplyr)

Election_2020 <- Election %>%
  filter(year == 2020) %>%
  filter(party == "DEMOCRAT" | party == "REPUBLICAN") %>%
  group_by(state, county_name, county_fips, party) %>%
  summarise(total_votes = sum(candidatevotes), .groups = 'drop') %>%
  group_by(state, county_name, county_fips) %>%
  slice(which.max(total_votes)) %>%
  select(county_fips, state, county_name, total_votes, party)

head(Election_2020,5)

```

Next I'm extracting the data I want from the **Unemployment1** dataset.
- Rename the dataset as to not alter the original
- Extracting the year from the Attribute column
- Filter and keep rows that have unemployment_rate
- Group by FIPS and summarize by year and keep if 2020 or else keep the max year
- Select columns want to keep: FIPS_Code, year, value
- Look at the 1st 5 entries of the new dataset. I'm hiding the output with results=FALSE to make it cleaner to read for the final document.

```{r, results=FALSE}

unemployment_data <- Unemployment1 %>%
  mutate(year = as.numeric(sapply(strsplit(Attribute, "_"), tail, 1))) %>%
  filter(grepl("Unemployment_rate", Attribute)) %>%
  group_by(FIPS_Code) %>%
  summarize(year = if_else(any(year == 2020), 2020, max(year[year < 2020], na.rm = TRUE)),
  Value = Value[which.max(year)]) %>%
  select(FIPS_Code, year, Value)

head(unemployment_data,5)
```

Next I'm extracting the data I want from the **Poverty** dataset.
- Rename the dataset as to not alter the original
- Filter and keep only data rows that have 'PCTPOVALL_2019 in the Attribute column
- Select which columns to keep and rename FIPStxt to County_FIPS
- Look at the 1st 5 entries of the new dataset. I'm hiding the output with results=FALSE to make it cleaner to read for the final document.
```{r, results=FALSE}

Poverty_2019 <- Poverty %>%
  filter(Attribute == "PCTPOVALL_2019") %>%
  select(FIPStxt, Value) %>%
  rename(County_FIPS = FIPStxt)

head(Poverty_2019,5)

```

Next I'm extracting the data I want from the **Education** dataset.
- Rename the dataset as to not alter the original
- Select which columns to keep
- Rename the columns to make it easier to understand and more concise
- Look at the 1st 5 entries of the new dataset. I'm hiding the output with results=FALSE to make it cleaner to read for the final document.

```{r}
Education_Data <- Education %>%
  select(
    FIPS.Code,
    Percent.of.adults.with.less.than.a.high.school.diploma..2015.19,
    Percent.of.adults.with.a.high.school.diploma.only..2015.19,
    Percent.of.adults.completing.some.college.or.associate.s.degree..2015.19,
    Percent.of.adults.with.a.bachelor.s.degree.or.higher..2015.19
  ) %>%
  rename(
    County_FIPS = FIPS.Code,
    Some_High_School = Percent.of.adults.with.less.than.a.high.school.diploma..2015.19,
    High_School_Diploma = Percent.of.adults.with.a.high.school.diploma.only..2015.19,
    Some_College = Percent.of.adults.completing.some.college.or.associate.s.degree..2015.19,
    College_Graduate = Percent.of.adults.with.a.bachelor.s.degree.or.higher..2015.19
  )
head(Education_Data,5)

```

Next I'm combining the 4 datasets to make 1 combined dataset called **combined_data**
- Using sql to combine the 4 datasets into 1 while renaming the variables so they match
- Look at the 1st 5 entries of the new dataset along w/ the summary of the dataset I'm hiding the output with results=FALSE to make it cleaner to read for the final document.

```{r, results=FALSE}
library(sqldf)
combined_data <- sqldf("
SELECT 
  Election_2020.county_fips AS FIPS_Code, 
  Election_2020.state, 
  Election_2020.county_name, 
  Election_2020.total_votes,
  Election_2020.party,
  unemployment_data.value AS unemployment_rate,
  Poverty_2019.Value AS poverty_rate,
  Education_Data.Some_High_School,
  Education_Data.High_School_Diploma,
  Education_Data.Some_College,
  Education_Data.College_Graduate
FROM Election_2020
  LEFT JOIN 
   unemployment_data ON Election_2020.county_fips = unemployment_data.FIPS_Code
  LEFT JOIN 
    Poverty_2019 ON Election_2020.county_fips = Poverty_2019.County_FIPS
  LEFT JOIN 
    Education_Data ON Election_2020.county_fips = Education_Data.County_FIPS")

head(combined_data,5)
summary(combined_data)


```














